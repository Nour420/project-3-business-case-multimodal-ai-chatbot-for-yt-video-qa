# -*- coding: utf-8 -*-
"""YT_QA_ChatBot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LEFl4Uj8bmxDsUvRzOWVzOOnSO0sPK0y
"""

# Essential installation.
!pip install yt-dlp
!pip install pinecone-client
!pip install langchain
!pip install langchain_openai
!pip install openai
!pip install wikipedia-api
!pip install langchain_community
!pip install transformers
!pip install pinecone-client

# Define API keys.
from google.colab import userdata
OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')
HF_TOKEN = userdata.get('HF_TOKEN')
LANGCHAIN_API_KEY = userdata.get('LANGCHAIN_API_KEY')
PINECONE_API_KEY = userdata.get('PINECONE_API_KEY')
YOUTUBE_API_KEY = userdata.get('YOUTUBE_API_KEY')

# Import necessary libraries.
import os
import re
import json
from tqdm import tqdm
from urllib.parse import urlparse, parse_qs
from googleapiclient.discovery import build
import yt_dlp
from transformers import WhisperProcessor, WhisperForConditionalGeneration, pipeline
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
import pinecone
import wikipediaapi
from langchain.agents import initialize_agent, AgentType, Tool
from langchain.memory import ConversationBufferMemory
from langchain.llms import OpenAI
import torch

def clean_text(text, for_filename=False):
    # Replace newlines and carriage returns with spaces.
    text = text.replace('\n', ' ').replace('\r', ' ')

    if for_filename:
        # Remove special characters for file names.
        text = ''.join(e for e in text if e.isalnum() or e.isspace())
    else:
        # Replace non-alphanumeric characters (except spaces) with spaces.
        text = re.sub(r'[^a-zA-Z0-9\s]', ' ', text)

    # Normalize multiple spaces into a single space.
    text = re.sub(r'\s+', ' ', text).strip()

    return text

def extract_video_id(url):
    query = urlparse(url).query
    params = parse_qs(query)
    return params.get('v', [None])[0]

def extract_playlist_id(url):
    query = urlparse(url).query
    params = parse_qs(query)
    return params.get('list', [None])[0]

# Metadata search and save.
def save_metadata(metadata_list, metadata_path):
    if not os.path.exists(metadata_path):
        os.makedirs(metadata_path)

    all_metadata_filename = os.path.join(metadata_path, 'all_metadata.json')
    with open(all_metadata_filename, 'w') as all_metadata_file:
        json.dump(metadata_list, all_metadata_file, indent=4)

def fetch_video_metadata(video_id, api_key, metadata_list):
    youtube = build('youtube', 'v3', developerKey=api_key)
    request = youtube.videos().list(
        part="snippet",
        id=video_id
    )
    response = request.execute()

    if not response['items']:
        print(f"No metadata found for video ID: {video_id}")
        return None

    item = response['items'][0]
    video_metadata = {
        'video_id': video_id,
        'title': clean_text(item['snippet']['title']),
        'description': clean_text(item['snippet']['description']),
        'published_at': item['snippet']['publishedAt']
    }

    metadata_list.append(video_metadata)
    return video_metadata

def fetch_playlist_metadata(playlist_id, api_key, metadata_list):
    youtube = build('youtube', 'v3', developerKey=api_key)
    request = youtube.playlistItems().list(
        part="snippet",
        playlistId=playlist_id,
        maxResults=50
    )

    while request:
        response = request.execute()
        for item in response['items']:
            video_id = item['snippet']['resourceId']['videoId']
            fetch_video_metadata(video_id, api_key, metadata_list)

        request = youtube.playlistItems().list_next(request, response)
    return metadata_list

"""Cell 3: YouTube Download Function"""

def download_from_youtube(download_path, metadata_path, api_key):
    video_url = "https://www.youtube.com/watch?v=GFLb5h2O2Ww&list=PLFs4vir_WsTyS2cy4vj4obl5igqCOV749"
    playlist_id = extract_playlist_id(video_url)
    metadata_list = []

    print("Fetching metadata...")
    fetch_playlist_metadata(playlist_id, api_key, metadata_list)
    save_metadata(metadata_list, metadata_path)
    print("Metadata saved successfully.")

    if not os.path.exists(download_path):
        os.makedirs(download_path)

    print("Downloading playlist from YouTube...")

    pbar = None

    def tqdm_hook(d):
        nonlocal pbar
        if d['status'] == 'downloading':
            if pbar is None:
                pbar = tqdm(total=d['total_bytes'], unit='B', unit_scale=True, unit_divisor=1024)
            pbar.update(d['downloaded_bytes'] - pbar.n)
        elif d['status'] == 'finished':
            if pbar:
                pbar.close()

    ydl_opts = {
        'format': 'bestaudio/best',
        'outtmpl': f'{download_path}/%(title)s.%(ext)s',
        'postprocessors': [{
            'key': 'FFmpegExtractAudio',
            'preferredcodec': 'mp3',
            'preferredquality': '192',
        }],
        'user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0',
        'verbose': True,
        'progress_hooks': [tqdm_hook]
    }

    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        ydl.download([video_url])

    print("Playlist downloaded successfully.")

    return metadata_list

metadata_path = './metadata'
download_path = './downloads'
pre_fetched_metadata = download_from_youtube(download_path, metadata_path, YOUTUBE_API_KEY)

"""Cell 4: Transcription Function"""

def transcribe_audio_hf(mp3_path, transcript_path):
    if not os.path.exists(transcript_path):
        os.makedirs(transcript_path)
    mp3_files = [f for f in os.listdir(mp3_path) if f.endswith('.mp3')]

    if not mp3_files:
        print("No MP3 files found for transcription.")
        return

    processor = WhisperProcessor.from_pretrained("openai/whisper-large-v3")
    model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-large-v3")
    feature_extractor = processor.feature_extractor

    # Dynamically select the device (handy for deployment environment).
    device = 0 if torch.cuda.is_available() else -1
    transcriber = pipeline("automatic-speech-recognition", model=model, tokenizer=processor.tokenizer, feature_extractor=feature_extractor, chunk_length_s=30, device=device)

    transcripts = []

    for mp3_file in tqdm(mp3_files, desc="Transcribing audio"):
        audio_path = os.path.join(mp3_path, mp3_file)
        print(f"Transcribing {mp3_file} located at {audio_path}...")

        try:
            # Generate transcription.
            transcript = transcriber(audio_path)
            transcript_text = transcript['text']
            cleaned_transcript = clean_text(transcript_text)

            # Add title (filename) and transcript to the transcripts list.
            transcripts.append({
                'title': os.path.splitext(mp3_file)[0],
                'transcript': cleaned_transcript
            })

            print(f"Transcription for {mp3_file} completed.")

        except Exception as e:
            print(f"Error transcribing {mp3_file}: {e}")

    # Save all transcripts to a single JSON file.
    all_transcripts_filename = os.path.join(transcript_path, 'all_transcripts.json')
    with open(all_transcripts_filename, 'w') as all_transcripts_file:
        json.dump(transcripts, all_transcripts_file, indent=4)

    print(f"All transcripts saved to {all_transcripts_filename}")

transcript_path = './transcripts'
transcribe_audio_hf(download_path, transcript_path)

"""Cell 5: Preprocessing and Embedding Function"""

def initialize_pinecone(api_key, index_name, dimension=1536):
    from pinecone import Pinecone, ServerlessSpec

    # Create an instance of the Pinecone class
    pc = Pinecone(api_key=api_key)

    # Check if the index already exists
    if index_name not in pc.list_indexes().names():
        pc.create_index(
            name=index_name,
            dimension=dimension,
            metric='cosine',
            spec=ServerlessSpec(
                cloud='aws',
                region='us-east-1'
            )
        )

    index = pc.Index(index_name)
    return index

pinecone_api_key = PINECONE_API_KEY
index_name = 'youtube-videos-data'

# Initialize Pinecone
index = initialize_pinecone(pinecone_api_key, index_name)

print("Pinecone index initialized successfully.")

def preprocess_and_embed(transcript_path, langchain_api_key):
    # Initialize the text splitter.
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=150)

    # Collect all transcripts.
    transcripts = []
    all_transcripts_filename = os.path.join(transcript_path, 'all_transcripts.json')
    if os.path.exists(all_transcripts_filename):
        with open(all_transcripts_filename, 'r') as all_transcripts_file:
            transcripts_data = json.load(all_transcripts_file)
            for item in transcripts_data:
                transcripts.append(item['transcript'])

    # Split and tokenize transcripts.
    text_chunks = []
    for transcript in transcripts:
        text_chunks.extend(text_splitter.split_text(transcript))

    embeddings_model = OpenAIEmbeddings(api_key=langchain_api_key)

    # Generate embeddings for each chunk.
    embeddings = embeddings_model.embed_documents(text_chunks)

    assert len(text_chunks) == len(embeddings), "Number of text chunks and embeddings do not match."

    return text_chunks, embeddings

# Test function.

langchain_api_key = OPENAI_API_KEY
# Call the function and check the output.
text_chunks, embeddings = preprocess_and_embed(transcript_path, langchain_api_key)

print(f"Number of text chunks generated: {len(text_chunks)}")

print("Text Chunks:")
for chunk in text_chunks[:5]:
    print(chunk)
    print()

print("Embeddings:")
for embedding in embeddings[:5]:
    print(embedding)
    print()

def upsert_embeddings(index, text_chunks, embeddings):
    # Upsert embeddings into Pinecone index.
    for i, (chunk, embedding) in enumerate(zip(text_chunks, embeddings)):
        index.upsert([(str(i), embedding, {'text': chunk})])

# Upsert embeddings.
upsert_embeddings(index, text_chunks, embeddings)

print("Embeddings upserted into Pinecone index.")

index.describe_index_stats()

!pip install -U langchain-openai
!pip install -U langchain-pinecone

from langchain_openai import OpenAIEmbeddings  # Updated import
from langchain_pinecone import Pinecone          # Updated import

text_field = 'text'
# Initialize the embeddings model
langchain_api_key = OPENAI_API_KEY
openai_embeddings = OpenAIEmbeddings(api_key=langchain_api_key)

# Initialize the vector store object
vectorstore = Pinecone(
    index, openai_embeddings, text_field  # Pass the instance directly
)

query = "what is immune system??"

vectorstore.similarity_search(
    query,  # our search query
    k=3  # return 3 most relevant docs
)

all_transcripts = './transcripts'

# Function to read transcripts from a single JSON file
def read_transcripts(transcript_file):
    # Construct the full path to the transcript file
    file_path = os.path.join(all_transcripts, transcript_file) # Use os.path.join to create the correct file path
    with open(file_path, 'r') as file:
        transcripts = json.load(file)
    return transcripts
'''
# Function to summarize text
def get_summary(transcript_file):
    summarizer = pipeline("summarization", model="facebook/bart-large-cnn")
    transcripts = read_transcripts(transcript_file)

    summaries = []
    for transcript in transcripts:
        summary = summarizer(transcript['transcript'], max_length=150, min_length=30, do_sample=False)[0]['summary_text']
        summaries.append(summary)

    return summaries


summarizer_tool = Tool(
    name="Summarizer",
    func=lambda x: get_summary(transcript_file=x), # Pass the filename to get_summary
    description="Summarize the content of transcripts. Find summaries based on user questions."
)
'''
# Initialize memory.
memory = ConversationBufferMemory()

# Initialize the language model using OpenAI with the specific model.
llm = OpenAI(api_key=OPENAI_API_KEY, temperature=0.7)

from langchain.chains import RetrievalQA
# Create the RetrievalQA instance with the language model and retriever
qa = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=vectorstore.as_retriever(),
    memory=memory  # Integrate the memory with RetrievalQA
)

# Define tools for the agent
tools = [
    Tool(
        name='video_transcript_retriever',
        func=qa.run,
        description='Searches and returns excerpts from the transcript of the user-uploaded video.'
    )
]

# Initialize the agent
agent = initialize_agent(
    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, memory=memory, verbose=True
)

print("QA Agent initialized successfully.")

query1 = "What are the potential negative impacts of getting a tattoo on the immune system?"


output1 = agent.run(query1)
print(output1)

query2 = "What is Ebola virus?"


output2 = qa.invoke(query2)
output2['result']

query3 = "Does the human body kill canser and how?"


output3 = qa.invoke(query3)
output3['result']

query4 = "Are the human immune against every disease?"


output4 = qa.invoke(query4)
output4['result']

query5 = "Why Cancer is so Hard to Beat?"


output5 = qa.invoke(query5)
output5['result']

!pip install -U langsmith

"""Evaluation:"""

#from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langsmith.evaluation import evaluate, LangChainStringEvaluator
from langchain.evaluation import load_evaluator


evaluator = load_evaluator("labeled_criteria", llm=llm, criteria="correctness")

from langsmith.evaluation import evaluate

evaluator = load_evaluator("labeled_criteria", llm=llm, criteria="conciseness")
evaluator = load_evaluator("labeled_criteria", llm=llm, criteria="coherence")

# Verify the type and content of output1
print(type(output1))
print(output1)

# If output1 is a string and contains a JSON-like structure, parse it
import json
try:
    output1_dict = json.loads(output1)
    val_result = evaluator.evaluate_strings(
        prediction=output1_dict['result'],
        input=query1,
        reference=""
    )
    print(val_result)
except json.JSONDecodeError:
    print("output1 is not a valid JSON string.")

print(type(output2))
print(output2)

output2_dict = output2
val_result = evaluator.evaluate_strings(
    prediction=output2_dict['result'],
    input=query2,
    reference=""
)
print(val_result)

print(type(output3))
print(output3)

output3_dict = output3
val_result = evaluator.evaluate_strings(
    prediction=output3_dict['result'],
    input=query3,
    reference=""
)
print(val_result)

print(type(output4))
print(output4)

output4_dict = output4
val_result = evaluator.evaluate_strings(
    prediction=output4_dict['result'],
    input=query4,
    reference=""
)
print(val_result)

print(type(output5))
print(output5)

output5_dict = output5
val_result = evaluator.evaluate_strings(
    prediction=output5_dict['result'],
    input=query5,
    reference=""
)
print(val_result)